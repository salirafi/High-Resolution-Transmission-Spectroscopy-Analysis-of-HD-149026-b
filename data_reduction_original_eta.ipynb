{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import batman\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import barycorrpy\n",
    "import astropy.time as time\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as fits\n",
    "import astropy.constants as const\n",
    "\n",
    "from scipy.stats import sigmaclip as sigmaclip\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm.notebook import tnrange\n",
    "\n",
    "from function import mask_pix\n",
    "from function import high_pass_filter\n",
    "from function import med_n_lim\n",
    "from function import solve_E\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Reduction():\n",
    "\n",
    "    def __init__(self,spectrum_path,Oliva_OH_path,Oliva_nonOH_path,Rousselot_OH_path,\n",
    "                 sum_order,bad_frame,bad_order,telluric_order,ref_cont,\n",
    "                 maskpix_value,resolution,edge_pix,factor_emission,factor_telluric,factor_outliers,sigma_threshold,\n",
    "                 threshold_heavy_low,threshold_nonheavy_low,threshold_heavy_ratio,threshold_nonheavy_ratio,\n",
    "                 binmedfil,bingauss,continuum_minimum,\n",
    "                 **kwargs):\n",
    "        \n",
    "        self.data_path = spectrum_path\n",
    "        self.sum_order = sum_order\n",
    "        self.bad_frame = bad_frame\n",
    "        self.bad_order = bad_order\n",
    "        self.tel_order = telluric_order\n",
    "        self.thold_hvy_low = threshold_heavy_low\n",
    "        self.thold_nhvy_low = threshold_nonheavy_low\n",
    "        self.thold_hvy_rat = threshold_heavy_ratio\n",
    "        self.thold_nhvy_rat = threshold_nonheavy_ratio\n",
    "        self.ref_cont = ref_cont\n",
    "        self.maskpix_val = maskpix_value\n",
    "        self.edge_pix = edge_pix\n",
    "        self.sig = sigma_threshold\n",
    "        self.res = resolution\n",
    "        self.fac_emis = factor_emission\n",
    "        self.fac_tel = factor_telluric\n",
    "        self.fac_out = factor_outliers\n",
    "        self.binmedfil = binmedfil\n",
    "        self.bingauss = bingauss\n",
    "        self.min_cont = continuum_minimum\n",
    "        self.OH_oliva = Oliva_OH_path\n",
    "        self.nonOH_oliva = Oliva_nonOH_path\n",
    "        self.OH_rousselot = Rousselot_OH_path\n",
    "        self.data_info = {}\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "    # function for masking emission wavelengths\n",
    "    def emission(self,wl,emis):\n",
    "        wv = np.array(emis)[(wl[0] < emis) * (wl[-1] > emis)]\n",
    "        mask = (np.prod(np.abs(wl - wv[:,np.newaxis]) > wv[:,np.newaxis]/self.res*self.fac_emis,axis=0)) == 1 # masking regions around the emission line bounded by eta*(lambda/R)\n",
    "        return mask\n",
    "\n",
    "    # function for opening and reading the spectrum FITS file\n",
    "    def data_prep(self):\n",
    "\n",
    "        dat_file = []\n",
    "        lst = os.listdir(self.data_path)\n",
    "        lst.sort()\n",
    "        for x in lst:\n",
    "            if not x.startswith('.') and x.endswith('.fits'):\n",
    "                dat_file.append(x)\n",
    "\n",
    "        # exclude bad frames\n",
    "        [dat_file.pop(frame) for frame in self.bad_frame]\n",
    "\n",
    "        flux,wave,error = [],[],[]\n",
    "        exptime,snr,airmass,mjd,jd,bjd,rvcor,seeing,humid,temp = [],[],[],[],[],[],[],[],[],[]\n",
    "\n",
    "        for idx,frame in enumerate(dat_file):\n",
    "            spec = fits.open(str(self.data_path)+str(frame))\n",
    "\n",
    "            flux_temp,wave_temp,error_temp = [],[],[]\n",
    "            for order in range(self.sum_order):\n",
    "                flux_temp.append(spec[1].data[order]) # flux\n",
    "                wave_temp.append(spec[4].data[order]) # wavelength\n",
    "                error_temp.append(spec[3].data[order]) # photon(+shot) noise\n",
    "            flux.append(flux_temp)\n",
    "            wave.append(wave_temp)\n",
    "            error.append(error_temp)\n",
    "\n",
    "            airmass.append(spec[0].header[\"AIRMASS\"]) # airmass at the observation start\n",
    "            exptime.append(spec[0].header[\"EXPTIME\"]) # exposure time\n",
    "            mjd.append(spec[0].header[\"HIERARCH CARACAL MJD-OBS\"]) # MJD at the observation start\n",
    "            rvcor.append(spec[0].header['HIERARCH CARACAL BERV']) # barycentric correction in to observer rest-frame\n",
    "            bjd.append(spec[0].header['HIERARCH CARACAL BJD']) # BJD at the observation start\n",
    "            jd.append(spec[0].header['HIERARCH CARACAL JD']) # JD at the observations start\n",
    "            humid.append(spec[0].header['HIERARCH CAHA GEN AMBI RHUM']) # relative humidity\n",
    "            temp.append(spec[0].header['HIERARCH CAHA GEN AMBI TEMPERATURE']) # ambient temperature\n",
    "\n",
    "            if frame.endswith(\"A.fits\"):\n",
    "                snr_temp = []\n",
    "                for i in range(self.sum_order):\n",
    "                    snr_temp.append(spec[0].header[\"HIERARCH CARACAL FOX SNR \"+str(i)]) # star SNR per pixel from CARACAL\n",
    "                snr.append(snr_temp)\n",
    "            elif frame.endswith(\"B.fits\"):\n",
    "                snr_temp = []\n",
    "                for i in range(self.sum_order):\n",
    "                    snr_temp.append(spec[0].header[\"HIERARCH CARACAL LXT SNR \"+str(i)]) # sky SNR per pixel from CARACAL\n",
    "                snr.append(snr_temp)\n",
    "\n",
    "        flux,wave,error = np.array(flux),np.array(wave),np.array(error)\n",
    "        print(flux.shape)\n",
    "        self.tot_init = flux.shape[2]*flux.shape[1]\n",
    "\n",
    "        flux_star = np.zeros((flux.shape[1],flux.shape[0],flux.shape[2])) # order x frame x wavelength\n",
    "        wave_star = flux_star.copy()\n",
    "        error_star = flux_star.copy()\n",
    "        for order in range(flux_star.shape[0]):\n",
    "            flux_star[order] = flux[:,order,:]\n",
    "            wave_star[order] = wave[:,order,:]\n",
    "            error_star[order] = error[:,order,:]\n",
    "\n",
    "        ref_spec = np.argmax(np.mean(snr,axis=1)) # reference spectrum taken as spectrum with highest mean SNR (over orders)\n",
    "        self.ref_spec = ref_spec\n",
    "        if self.__dict__['plot_prep']:\n",
    "\n",
    "            # plot humidity and airmass\n",
    "            fig,(ax1,ax2) = plt.subplots(1,2,figsize=(20,5))\n",
    "            ax1.scatter(np.arange(len(bjd)),humid)\n",
    "            ax1.set_title('Humidity')\n",
    "            ax2.scatter(np.arange(len(bjd)),airmass)\n",
    "            ax2.set_title('Airmass')\n",
    "            print('Average humidity is '+str(np.mean(humid)))\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "\n",
    "            plt.figure(figsize=(15,10))\n",
    "            print('Mean SNR over all frames and orders: '+str(np.mean(snr)))\n",
    "            print('Frame with the highest SNR: '+str(np.argmax(np.mean(snr,axis=1)))+' ('+str(dat_file[np.argmax(np.mean(snr,axis=1))])+')')\n",
    "\n",
    "            # plot average SNR over frames for every orders\n",
    "            plt.subplot(211)\n",
    "            plt.scatter(np.arange(len(snr[0])),np.mean(snr,axis=0))\n",
    "            plt.plot(np.mean(snr,axis=0))\n",
    "            plt.axhline(y=50,ls='--',lw=1)\n",
    "            plt.ylabel(\"snr\")\n",
    "            plt.xlabel(\"order\")\n",
    "            plt.title('SNR')\n",
    "\n",
    "            # plot average SNR over orders for every frames\n",
    "            plt.subplot(212)\n",
    "            plt.scatter(np.arange(len(snr)),np.mean(snr,axis=1))\n",
    "            plt.plot(np.mean(snr,axis=1))\n",
    "            plt.ylabel(\"snr\")\n",
    "            plt.xlabel(\"frame\")\n",
    "            plt.title('SNR')\n",
    "\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "\n",
    "            plt.figure(figsize=(15,5),dpi=300)\n",
    "            for order in range(len(flux_star)):\n",
    "                if order not in self.bad_order:\n",
    "                    plt.plot(wave_star[order][ref_spec],flux_star[order][ref_spec],color='black',lw=1)\n",
    "                else:\n",
    "                    plt.plot(wave_star[order][ref_spec],flux_star[order][ref_spec],color='gray',lw=1)\n",
    "                    # plt.fill_betweenx(np.arange(0.1),wave_star[order][41][0],wave_star[order][41][-1],color='green',alpha=0.4,edgecolor='none')\n",
    "                \n",
    "            plt.ylabel('Arbitrary flux')\n",
    "            plt.xlabel(r'Wavelength ($\\AA$)')\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "\n",
    "        self.data_info['airmass'] = np.asarray(airmass)\n",
    "        self.data_info['humid'] = np.asarray(humid)\n",
    "        self.data_info['exptime'] = np.asarray(exptime)\n",
    "        self.data_info['SNR'] = np.asarray(snr)\n",
    "        self.data_info['MJD'] = np.asarray(mjd)\n",
    "        self.data_info['JD'] = np.asarray(jd)\n",
    "        self.data_info['BJD'] = np.asarray(bjd)\n",
    "        self.data_info['RV_cor'] = np.asarray(rvcor)\n",
    "        self.data_info['temperature'] = np.asarray(temp)\n",
    "        return flux_star, error_star, wave_star, snr, airmass, humid, self.data_info \n",
    "\n",
    "    # function for reducing the data (includes normalizing, masking, and uncertainty estimation)\n",
    "    def normalization_and_masking(self):\n",
    "\n",
    "        flux_temp, error, wave, snr, airmass, humid, self.data_info = self.data_prep()\n",
    "        flux = flux_temp.copy()\n",
    "        ref_spec = self.ref_spec\n",
    "        ref_cont = self.ref_cont\n",
    "\n",
    "        for order in range(flux.shape[0]):\n",
    "\n",
    "            ######################################## Spectrum normalizing ########################################\n",
    "            \n",
    "            # plot photon noise from CARACAL\n",
    "            if self.__dict__['plot_norm']:\n",
    "                plt.figure(figsize=(25,5))\n",
    "                plt.subplot(131)\n",
    "                plt.plot(wave[order][ref_spec],error[order][ref_spec])\n",
    "\n",
    "                plt.subplot(132)\n",
    "                plt.plot(wave[order][ref_spec],flux[order][ref_spec],linewidth=1)\n",
    "                plt.plot(wave[order][ref_spec],ref_cont[0].data[order])\n",
    "                plt.title(\"order #\"+str(order))\n",
    "\n",
    "            # normalizing with pseudo-continuum\n",
    "            error[order] /= ref_cont[0].data[order]\n",
    "            flux[order] /= ref_cont[0].data[order]\n",
    "\n",
    "            for frame in range(len(flux[order])):\n",
    "\n",
    "                # to minimize contributions from outliers and spectral lines to the median computation\n",
    "                medflux = np.nanmedian(flux[order][frame][500:-500][np.argsort(flux[order][frame][500:-500])][500:])\n",
    "\n",
    "                # removing variations between frames\n",
    "                error[order][frame] /= medflux\n",
    "                flux[order][frame] /= medflux\n",
    "\n",
    "            # plot IRAF pseudo-continuum fitted using continuum task\n",
    "            if self.__dict__['plot_norm']:\n",
    "                plt.subplot(133)\n",
    "                plt.plot(wave[order][ref_spec],flux[order][ref_spec])\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "        ######################################## Nan and negative values masking ########################################\n",
    "\n",
    "        if self.__dict__['print_neg']:\n",
    "            for order in range(len(flux)):\n",
    "                print('order '+str(order)+', negative_count = '+str(np.count_nonzero(flux[order] < 0))\\\n",
    "                +', nan_count = '+str(np.count_nonzero(np.isnan(flux[order]))))\n",
    "\n",
    "        mask = ((np.prod(~np.isnan(flux),axis=1))==1) * ((np.prod(flux>=0,axis=1))==1)\n",
    "        mask = np.repeat(mask[:,np.newaxis,:],repeats=[flux.shape[1]],axis=1)\n",
    "        flux[~mask],error[~mask] = self.maskpix_val,np.inf\n",
    "\n",
    "        ######################################## Removing bad orders ########################################\n",
    "\n",
    "        flux = np.delete(flux,self.bad_order,0)\n",
    "        error = np.delete(error,self.bad_order,0)\n",
    "        wave = np.delete(wave,self.bad_order,0)\n",
    "        self.carm_order = np.delete(np.arange(flux_temp.shape[0]),self.bad_order,0)\n",
    "\n",
    "        ######################################## Sky emission masking ########################################\n",
    "\n",
    "        # atlas from Oliva+ (2015)\n",
    "        OH_1st,OH_2nd,nonOH = [],[],[]\n",
    "        for i in range(len(self.OH_oliva)):\n",
    "            OH_1st.append(self.OH_oliva[i][0]) # first OH doublet\n",
    "            OH_2nd.append(self.OH_oliva[i][2]) # second OH doublet\n",
    "        for i in range(len(self.nonOH_oliva)):\n",
    "            nonOH.append(self.nonOH_oliva[i][0]) # non-OH emission\n",
    "\n",
    "        # atlas from Rousselot+ (2000)\n",
    "        OH_rous = []\n",
    "        for i in range(len(self.OH_rousselot)):\n",
    "            OH_rous.append(self.OH_rousselot[i][0])\n",
    "\n",
    "        for order in range(len(flux)):\n",
    "            \n",
    "            # only use a single frame to mask as sky emission wavelengths are not changing over time\n",
    "            mask = self.emission(wave[order][0],OH_1st) # OH 1st doublet\n",
    "            mask *= self.emission(wave[order][0],OH_2nd) # OH 2nd doublet\n",
    "            mask *= self.emission(wave[order][0],nonOH) # non-OH\n",
    "            mask *= self.emission(wave[order][0],OH_rous) # atlas from Rousselot+ (2000)\n",
    "\n",
    "            error[order][:,~mask] = np.inf\n",
    "            flux[order][:,~mask] = self.maskpix_val\n",
    "\n",
    "        if self.__dict__['plot_emis']:\n",
    "            for idx,order in enumerate(self.carm_order):\n",
    "\n",
    "                plt.figure(figsize=(20,5))\n",
    "                for frame in range(len(flux[idx])):\n",
    "                    plt.plot(wave[idx][frame][flux[idx][frame]!=0],flux[idx][frame][flux[idx][frame]!=0],'black',linewidth=1,alpha=1)\n",
    "                plt.title(order)\n",
    "\n",
    "                for wv in OH_1st:\n",
    "                    plt.axvline(x=wv,linewidth=1,alpha=0.7,c='b')\n",
    "                for wv in OH_2nd:\n",
    "                    plt.axvline(x=wv,linewidth=1,alpha=0.7,c='b')\n",
    "                for wv in nonOH:\n",
    "                    plt.axvline(x=wv,linewidth=1,alpha=0.7,c='r')\n",
    "                for wv in OH_rous:\n",
    "                    plt.axvline(x=wv,linewidth=1,alpha=0.7,c='cyan')\n",
    "                plt.xlim(wave[idx][ref_spec][0],wave[idx][ref_spec][-1])\n",
    "\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "        ######################################## Bad regions masking (SUBJECT TO CHANGE) ########################################\n",
    "\n",
    "        for order in range(len(self.carm_order)):\n",
    "\n",
    "            if self.__dict__['plot_bad_reg']:\n",
    "                plt.figure(figsize=(20,5))\n",
    "                for frame in range(flux.shape[1]):\n",
    "                    plt.scatter(wave[order][frame][flux[order][frame]!=0],flux[order][frame][flux[order][frame]!=0],s=1,c='red')\n",
    "            \n",
    "            mask = flux[order][0] < np.inf\n",
    "            mask[:self.edge_pix] = False                                        # edge-effects of CARMENES orders (Sanchez-Lopez+ 2019)\n",
    "            mask[-self.edge_pix:] = False                                       # edge-effects of CARMENES orders (Sanchez-Lopez+ 2019)\n",
    "            if order == 21: mask[-1000:] = False                                # low SNR regions\n",
    "            elif order == 20: mask[-350:] = False                               # low SNR regions\n",
    "            elif order == 2 or order == 3 or order == 4: mask[:545] = False     # un-natural bumps in bluest parts\n",
    "\n",
    "            error[order][:,~mask] = np.inf\n",
    "            flux[order][:,~mask] = self.maskpix_val\n",
    "\n",
    "            if self.__dict__['plot_bad_reg']:\n",
    "                for frame in range(flux.shape[1]):\n",
    "                    plt.scatter(wave[order][frame][flux[order][frame]!=0],flux[order][frame][flux[order][frame]!=0],s=1,c='blue')\n",
    "                plt.title('order '+str(self.carm_order[order]))\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "        ######################################## Outliers masking ########################################\n",
    "        \n",
    "        for idx,order in enumerate(self.carm_order):\n",
    "\n",
    "            if self.__dict__['plot_out']:\n",
    "                fig,ax = plt.subplots(1,3,figsize=(15,5))\n",
    "                for frame in range(len(flux[idx])):\n",
    "                    ax[0].plot(wave[idx][frame][flux[idx][frame]>0],flux[idx][frame][flux[idx][frame]>0])\n",
    "\n",
    "            # removing cosmic rays (cosmic rays behaviour only seen in one or two frames hence it's treated differently)\n",
    "            flux_temp = np.copy(flux[idx])\n",
    "            for wave_bin in range(flux_temp.shape[1]):\n",
    "                c = sigmaclip(flux_temp[:,wave_bin],low=self.sig,high=self.sig)[0]\n",
    "                flux[idx][:,wave_bin],error[idx][:,wave_bin] = (self.maskpix_val,np.inf) if ~(np.abs(flux_temp[:,wave_bin]-np.mean(c))<self.sig*np.std(c)).all()\\\n",
    "                else (flux[idx][:,wave_bin],error[idx][:,wave_bin])\n",
    "\n",
    "            # identify outliers following Gibson+ (2020) but instead using std of the residual\n",
    "            wv,fl,er,maskpix = mask_pix(wave[idx],flux[idx],error[idx])\n",
    "            simple_model = np.outer(np.median(fl,axis=1),np.median(fl,axis=0))/np.median(fl)\n",
    "            residual = fl - simple_model\n",
    "            mask = np.abs(residual[0]) > -1\n",
    "            for frame in range(fl.shape[0]):\n",
    "                fit = np.polyfit(wv[frame], residual[frame], 10) # fit with 10th order polynomial\n",
    "                fit_coeff = np.poly1d(fit)\n",
    "                fit_continuum = fit_coeff(wv[frame])\n",
    "                mask *= (residual[frame] < fit_continuum + self.sig*np.std(residual[frame])) *  (residual[frame] > fit_continuum - self.sig*np.std(residual[frame]))\n",
    "\n",
    "                if self.__dict__['plot_out'] and frame == self.ref_spec:\n",
    "                    ax[1].plot(wv[frame],residual[frame])\n",
    "                    ax[1].plot(wv[frame],fit_continuum)\n",
    "                    ax[1].plot(wv[frame],fit_continuum+self.sig*np.std(residual[frame]))\n",
    "                    ax[1].plot(wv[frame],fit_continuum-self.sig*np.std(residual[frame]))\n",
    "            mask = ~mask\n",
    "\n",
    "            # identify line center by median centering\n",
    "            if True in mask:\n",
    "                wv_len = wv[0,mask]\n",
    "                wv_idx,wv_med,wv_temp = 0,[],[wv_len[0]]\n",
    "                if len(wv_len) == 1:\n",
    "                    wv_med.append(wv_len[0])\n",
    "                else:\n",
    "                    while wv_idx < len(wv_len)-1:\n",
    "                        if wv_len[wv_idx+1]-wv_len[wv_idx] < wv_len[wv_idx]/self.res*self.fac_out/2:\n",
    "                            wv_temp.append(wv_len[wv_idx+1])\n",
    "                            wv_idx += 1\n",
    "                        else:\n",
    "                            wv_med.append(np.median(wv_temp))\n",
    "                            wv_temp = [wv_len[wv_idx+1]]\n",
    "                            wv_idx += 1\n",
    "                    wv_med.append(wv_len[-1])\n",
    "\n",
    "                # masking regions around outlier\n",
    "                wv_med = np.array(wv_med)\n",
    "                maskcen = ~((np.prod(np.abs(wv[0]-wv_med[:,np.newaxis]) > wv_med[:,np.newaxis]/self.res*self.fac_out/2,axis=0)) == 1)\n",
    "                fl[:,maskcen],er[:,maskcen] = self.maskpix_val, np.inf\n",
    "            else:\n",
    "                fl[:,mask],er[:,mask] = self.maskpix_val, np.inf\n",
    "\n",
    "            # assign the new value to the original array\n",
    "            for frame in range(fl.shape[0]):\n",
    "                error[idx][frame][maskpix==True] = er[frame]\n",
    "                flux[idx][frame][maskpix==True] = fl[frame]\n",
    "                \n",
    "                if self.__dict__['plot_out']:\n",
    "                    ax[0].set_title('order #'+str(order))\n",
    "                    ax[2].plot(wave[idx][frame][flux[idx][frame]>0],flux[idx][frame][flux[idx][frame]>0])\n",
    "\n",
    "        ######################################## Mask strong telluric absorption lines ########################################\n",
    "\n",
    "            if self.__dict__['plot_strong_tel']:\n",
    "                plt.figure(figsize=(15,3))\n",
    "\n",
    "            wv,fl,er,maskpix = mask_pix(wave[idx],flux[idx],error[idx])\n",
    "\n",
    "            # mask strong telluric lines\n",
    "            masklow = np.min(fl,axis=0) > self.thold_hvy_low if order in self.tel_order\\\n",
    "                else np.min(fl,axis=0) > self.thold_nhvy_low\n",
    "            \n",
    "            continum = np.zeros(fl.shape)\n",
    "            for frame in range(fl.shape[0]):\n",
    "\n",
    "                # compute pseudo-continuum for strong telluric masking (see common_continuum function)\n",
    "                med_fil = high_pass_filter(fl[frame][masklow],self.binmedfil)\n",
    "                gauss_fil = gaussian_filter1d(med_fil,self.bingauss)\n",
    "                continum[frame] = interp1d(wv[frame][masklow],gauss_fil,fill_value='extrapolate')(wv[frame])\n",
    "\n",
    "            # masking the core of strong telluric lines (pixels with flux less than a certain threshold)\n",
    "            masktel = ~((np.prod(fl>self.min_cont*continum,axis=0))==1)\n",
    "\n",
    "            # identify line center by median centering\n",
    "            if True in masktel:\n",
    "                wv_len = wv[0,masktel]\n",
    "                wv_idx,wv_med,wv_temp = 0,[],[wv_len[0]]\n",
    "                if len(wv_len) == 1:\n",
    "                    wv_med.append(wv_len[0])\n",
    "                else:\n",
    "                    while wv_idx < len(wv_len)-1:\n",
    "                        if wv_len[wv_idx+1]-wv_len[wv_idx] < wv_len[wv_idx]/self.res*self.fac_tel/2:\n",
    "                            wv_temp.append(wv_len[wv_idx+1])\n",
    "                            wv_idx += 1\n",
    "                        else:\n",
    "                            wv_med.append(np.median(wv_temp))\n",
    "                            wv_temp = [wv_len[wv_idx+1]]\n",
    "                            wv_idx += 1\n",
    "                    wv_med.append(wv_len[-1])\n",
    "\n",
    "                # masking lines\n",
    "                wv_med = np.array(wv_med)\n",
    "                maskcen = ~((np.prod(np.abs(wv[0]-wv_med[:,np.newaxis]) > wv_med[:,np.newaxis]/self.res*self.fac_tel/2,axis=0)) == 1)\n",
    "                if self.__dict__['plot_strong_tel']:\n",
    "                    [plt.scatter(wv[frame][maskcen],fl[frame][maskcen],s=1,c='black') for frame in range(fl.shape[0])]\n",
    "                    [plt.axvline(x=wvmask) for wvmask in wv_med]\n",
    "                fl[:,maskcen],er[:,maskcen] = self.maskpix_val, np.inf\n",
    "            else:\n",
    "                fl[:,masktel],er[:,masktel] = self.maskpix_val, np.inf\n",
    "\n",
    "            for frame in range(len(flux[idx])):\n",
    "                error[idx][frame][maskpix==True] = er[frame]\n",
    "                flux[idx][frame][maskpix==True] = fl[frame]\n",
    "\n",
    "            wv,fl,er,maskpix = mask_pix(wv,fl,er)\n",
    "            if self.__dict__['plot_strong_tel']:\n",
    "                plt.title(self.carm_order[idx])\n",
    "                [plt.scatter(wv[frame],fl[frame],s=1,c='green') for frame in range(fl.shape[0])]\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "        return flux,error,wave\n",
    "    \n",
    "    # function for putting the spectrum continuum to common level (smallest magnitude difference possible)\n",
    "    def common_continuum(self):\n",
    "\n",
    "        flux,error,wave = self.normalization_and_masking()\n",
    "        for idx,order in enumerate(self.carm_order):\n",
    "            wv,fl,er,maskpix = mask_pix(wave[idx],flux[idx],error[idx])\n",
    "\n",
    "            # mask strong telluric lines\n",
    "            masklow = np.min(fl,axis=0) > self.thold_hvy_low if order in self.tel_order\\\n",
    "                else np.min(fl,axis=0) > self.thold_nhvy_low\n",
    "            \n",
    "            # define the master spectrum (Gibson+ 2018)\n",
    "            master = np.median(fl,axis=0)\n",
    "            \n",
    "            if self.__dict__['plot_conti']:\n",
    "                plt.figure(figsize=(20,5))\n",
    "                for frame in range(len(fl)):\n",
    "                    plt.plot(wv[frame],fl[frame],alpha=0.7,lw=1,c='black')\n",
    "                plt.plot(wv[0],master,lw=2)\n",
    "                plt.title('Order #'+str(order))\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "                fig,ax = plt.subplots(1,3,figsize=(20,5))\n",
    "                \n",
    "            for frame in range(fl.shape[0]):\n",
    "\n",
    "                # calculate ratio\n",
    "                ratio = fl[frame][masklow]/master[masklow]\n",
    "\n",
    "                # mask telluric lines not removed by the previous masking\n",
    "                maskrat = np.abs(ratio-np.median(ratio)) < self.thold_hvy_rat if order in self.tel_order\\\n",
    "                    else np.abs(ratio-np.median(ratio)) < self.thold_nhvy_rat\n",
    "\n",
    "                # applying high-pass filter\n",
    "                med_fil = high_pass_filter(ratio[maskrat],self.binmedfil)\n",
    "\n",
    "                # applying gaussian filter to further smooth the spectrum\n",
    "                gauss_fil = gaussian_filter1d(med_fil,self.bingauss)\n",
    "\n",
    "                # interpolating the filter to the original wavelength array\n",
    "                conti = interp1d(wv[frame][masklow][maskrat],gauss_fil,fill_value='extrapolate')(wv[frame])\n",
    "\n",
    "                # putting to common level\n",
    "                er[frame] /= conti\n",
    "                fl[frame] /= conti\n",
    "\n",
    "                # assign the new value to the original array\n",
    "                error[idx][frame][maskpix==True] = er[frame]\n",
    "                flux[idx][frame][maskpix==True] = fl[frame]\n",
    "\n",
    "                if self.__dict__['plot_conti']:\n",
    "                    ax[0].plot(wv[frame][masklow][maskrat],ratio[maskrat],lw=1,alpha=0.5)\n",
    "                    ax[0].set_title(order)\n",
    "                    ax[1].plot(wv[frame],conti)\n",
    "\n",
    "                    ratio = fl[frame][masklow]/master[masklow]\n",
    "                    maskrat = np.abs(ratio-np.median(ratio)) < self.thold_hvy_rat if order in self.tel_order\\\n",
    "                    else np.abs(ratio-np.median(ratio)) < self.thold_nhvy_rat\n",
    "                    med_fil = high_pass_filter(ratio[maskrat],self.binmedfil)\n",
    "                    gauss_fil = gaussian_filter1d(med_fil,self.bingauss)\n",
    "                    conti = interp1d(wv[frame][masklow][maskrat],gauss_fil,fill_value='extrapolate')(wv[frame])\n",
    "                    ax[2].plot(wv[frame],conti) # plotting the resulting continuum\n",
    "\n",
    "            if self.__dict__['plot_conti']:\n",
    "                plt.figure(figsize=(20,5))\n",
    "                plt.scatter(wave[idx][0],np.median(flux[idx],axis=0)-1,s=1)\n",
    "                plt.ylabel('median flux')\n",
    "                plt.yscale(\"log\")\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "        return flux,error,wave\n",
    "\n",
    "    # function for estimating uncertainties using outer product\n",
    "    def error_estimate(self,common_conti):\n",
    "\n",
    "        flux,error,wave = self.common_continuum() if common_conti else self.normalization_and_masking()\n",
    "        \n",
    "        error_outer_temp = np.zeros(flux.shape)\n",
    "        for order in range(len(flux)):\n",
    "\n",
    "            fl = flux[order].copy()\n",
    "            fl[error[order]==np.inf] = np.nan\n",
    "            error_outer_temp[order] = np.outer(np.nanstd(fl,axis=1),np.nanstd(fl,axis=0))/np.nanstd(fl)\n",
    "        \n",
    "        error_outer = np.nan_to_num(error_outer_temp, nan=np.inf)\n",
    "\n",
    "        if self.__dict__['plot_error']:\n",
    "\n",
    "            # to check the difference between photon noise from CARACAL and outer product estimation\n",
    "            for order in range(flux.shape[0]):\n",
    "                plt.figure(figsize=(15,5))\n",
    "                plt.plot(wave[order][self.ref_spec],error_outer[order][self.ref_spec],label='Uncertainty from outer product',c='black')\n",
    "                plt.plot(wave[order][self.ref_spec],error[order][self.ref_spec],label='Reduction pipeline uncertainty propagated through the preparation')\n",
    "                plt.ylabel('Error')\n",
    "                plt.xlabel(r'Wavelength ($\\AA$)')\n",
    "                plt.title('Order '+str(self.carm_order[order]))\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "        return flux,error,error_outer,wave\n",
    "    \n",
    "    # performing the reduction procedures described above\n",
    "    def perform_reduction(self,print_mask_count=True,common_conti=True):\n",
    "\n",
    "        flux, error, error_outer, wave = self.error_estimate(common_conti)\n",
    "        self.data_info['CARMENES_order'] = self.carm_order\n",
    "\n",
    "        if print_mask_count:\n",
    "            tot_fin = int(flux.shape[0]*flux.shape[2]-np.sum(error == np.inf)/flux.shape[1])\n",
    "            print(\"For each spectrum, before the masking = \"+str(self.tot_init)+\", after masking = \"\\\n",
    "                +str(tot_fin)+\" (\"+str(round(((self.tot_init-tot_fin)/self.tot_init)*100,2))+\"% non-useful data points).\")\n",
    "        \n",
    "        return flux, error, error_outer, wave, self.data_info\n",
    "    \n",
    "    # function for checking the wavelength stability\n",
    "    def wave_stability_check(self, model_path, RV_sample, A_sample):\n",
    "        \n",
    "        # reading the telluric template\n",
    "        with h5py.File(model_path, 'r') as h5f_raw:\n",
    "            modflux_tel = h5f_raw['flux'][()]\n",
    "            modwave_tel = h5f_raw['wv'][()]\n",
    "\n",
    "        K1_all,K2_all,CC_all,N_data = [],[],[],[]\n",
    "        \n",
    "        self.min_cont = 0.0     # no lines are masked\n",
    "        self.fac_out = 2        # case-sensitive\n",
    "        flux, error, error_outer, wave, self.data_info = self.perform_reduction(print_mask_count=False)\n",
    "\n",
    "        for idx,order in enumerate(self.tel_order): # only use orders with heavy telluric contamination\n",
    "\n",
    "            # using uncertainty from outer error\n",
    "            order_idx = np.where(np.asarray(self.carm_order)==order)[0][0]\n",
    "            wave_obs,flux_obs,error_obs,maskpix = mask_pix(wave[order_idx],flux[order_idx],error_outer[order_idx])\n",
    "\n",
    "            # masking model to the corresponding order wavelength\n",
    "            masktemp = (modwave_tel > wave_obs[0][0] - 20) * (modwave_tel < wave_obs[0][-1] + 20)\n",
    "            wave_mod,flux_mod = modwave_tel[masktemp],modflux_tel[masktemp]\n",
    "        \n",
    "            # Doppler-shifting the model (dimensions: RV_sample x wave_mod_shifted)\n",
    "            wave_mod_shifted = wave_obs[0][np.newaxis,:] / (1 + RV_sample*1000/const.c.value)[:,np.newaxis]\n",
    "            flux_mod_shifted = interp1d(wave_mod,flux_mod)(wave_mod_shifted)\n",
    "\n",
    "            # making model and data to a common mean\n",
    "            flux_mod_shifted -= np.nanmean(flux_mod_shifted,axis=1)[:,np.newaxis]\n",
    "            flux_obs -= np.nanmean(flux_obs,axis=1)[:,np.newaxis]\n",
    "\n",
    "            # calculating the summation terms in the chi^2 equation (Gibson+ 2020)\n",
    "            K1 = np.nansum(flux_obs**2/error_obs**2,axis=1)\n",
    "            K2 = np.dot(1./error_obs**2,np.square(flux_mod_shifted).T)\n",
    "            CC = np.dot(flux_obs/error_obs**2,flux_mod_shifted.T)\n",
    "\n",
    "            if self.__dict__['plot_shift']:\n",
    "                plt.figure(figsize=(20,5))\n",
    "                plt.plot(wave_obs[self.ref_spec],flux_obs[self.ref_spec],label='Data')\n",
    "                plt.plot(wave_obs[self.ref_spec],flux_mod_shifted[np.argmax(CC[self.ref_spec])],label='Model')\n",
    "                plt.title('Shift based on maximum CCF value - Order '+str(self.carm_order[order_idx]))\n",
    "                plt.xlabel(r'Wavelength $\\AA$')\n",
    "                plt.ylabel('Normalized flux')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "            K1_all.append(K1) # dimensions: order x frame\n",
    "            K2_all.append(K2) # dimensions: order x frame x RV_sample\n",
    "            CC_all.append(CC) # dimensions: order x frame x RV_sample\n",
    "            N_data.append(len(wave_obs[self.ref_spec]))\n",
    "\n",
    "        # summing over the orders\n",
    "        K1_total = np.sum(K1_all,axis=0)\n",
    "        K2_total = np.sum(K2_all,axis=0)\n",
    "        CC_total = np.sum(CC_all,axis=0)\n",
    "        N_data_total = np.sum(N_data)\n",
    "\n",
    "        # calculating the likelihood for each frame\n",
    "        RV_shift = np.zeros(K1_total.size)\n",
    "        for frame in tnrange(K1_total.size,ascii=True,desc='Frame'):\n",
    "\n",
    "            # calculate chi^2 (dimensions: A_sample x RV_sample)\n",
    "            chi_2 = K1_total[frame] + A_sample[:,np.newaxis]**2 * K2_total[frame][np.newaxis,:]\\\n",
    "            - 2 * A_sample[:,np.newaxis] * CC_total[frame][np.newaxis,:]\n",
    "\n",
    "            # calculate log-likelihood\n",
    "            logL = -N_data_total / 2 * np.log(chi_2/N_data_total)\n",
    "\n",
    "            # normalizing by the maximum value and convert to likelihood\n",
    "            likelihood = np.exp(logL - np.max(logL))\n",
    "\n",
    "            # marginilising the likelihood over the scale factor to get the marginalised likelihood for RV_sample\n",
    "            RV_marg = np.sum(likelihood,axis=0)\n",
    "            A_marg = np.sum(likelihood,axis=1) # same but for scale factor\n",
    "\n",
    "            # extracting the conditional likelihood at the maximum point of the marginalised RV_sample\n",
    "            A_cond = likelihood[:,np.argmax(RV_marg)]\n",
    "\n",
    "            # extracting the +- error and median of RV and the corresponding scale factor\n",
    "            low_RV,med_RV,high_RV = med_n_lim(RV_sample,RV_marg)\n",
    "\n",
    "            if self.__dict__['plot_shift']:\n",
    "                low_A,med_A,high_A = med_n_lim(A_sample,A_marg)\n",
    "\n",
    "                plt.figure(figsize=(20,5))\n",
    "                plt.subplot(121)\n",
    "                plt.plot(RV_sample,RV_marg)\n",
    "                plt.title('Frame '+str(frame))\n",
    "                plt.title('Frame '+str(frame))\n",
    "                plt.xlabel('RV')\n",
    "                plt.xlim(med_RV+5*low_RV, med_RV+5*high_RV)\n",
    "                plt.subplot(122)\n",
    "                plt.plot(A_sample,A_marg)\n",
    "                plt.xlabel(r'$\\alpha$')\n",
    "                plt.xlim(med_A+5*low_A, med_A+5*high_A)\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "            RV_shift[frame] = med_RV\n",
    "\n",
    "        mean_RV_shift = np.mean(RV_shift)\n",
    "\n",
    "        fig, ax1 = plt.subplots(figsize=(7,4),dpi=300)\n",
    "        ax1.errorbar(np.arange(RV_shift.size),np.array(RV_shift),\n",
    "                    np.std(RV_shift),fmt='v',color='black',xuplims=True, xlolims=True,alpha=0.7,label=\"Likelihood RV\")\n",
    "        ax1.axhline(y=mean_RV_shift,ls='--',color='red',alpha=0.8,label='Mean RV shift = '+str(round(mean_RV_shift,4))+' km/s')\n",
    "        ax1.set_xlabel('Frame number')\n",
    "        ax1.set_ylabel('Telluric RV (km/s)')\n",
    "\n",
    "        ax1.minorticks_on()\n",
    "        ax1.tick_params(which=\"both\",direction='in',width=1)\n",
    "        ax1.tick_params(which=\"major\",length=6,direction='in')\n",
    "        ax1.tick_params(which=\"minor\",length=3,direction='in')\n",
    "        ax1.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"figures/wavelength_stability.pdf\",format=\"pdf\",dpi=200,bbox_inches=\"tight\",pad_inches=0.1)\n",
    "        plt.show(block=False)\n",
    "        plt.clf()\n",
    "\n",
    "    def stellar_RV(self, modwave_stellar, modflux_stellar, RV_sample, A_sample, phase, rel_phase, *param):\n",
    "\n",
    "        K1_all,K2_all,CC_all,N_data = [],[],[],[]\n",
    "\n",
    "        self.min_cont = 0.0     # no lines are masked\n",
    "        self.fac_out = 2        # case-sensitive\n",
    "        flux, error, error_outer, wave, self.data_info = self.perform_reduction(print_mask_count=False)\n",
    "\n",
    "        for idx,order in enumerate(self.carm_order):\n",
    "\n",
    "            # using uncertainty from outer error\n",
    "            order_idx = np.where(np.asarray(self.carm_order)==order)[0][0]\n",
    "            wave_obs,flux_obs,error_obs,maskpix = mask_pix(wave[order_idx],flux[order_idx],error_outer[order_idx])\n",
    "\n",
    "            # masking model to the corresponding order wavelength\n",
    "            masktemp = (modwave_stellar > wave_obs[0][0] - 20) * (modwave_stellar < wave_obs[0][-1] + 20)\n",
    "            wave_mod,flux_mod = modwave_stellar[masktemp],modflux_stellar[masktemp]\n",
    "\n",
    "            # Doppler-shifting the model (dimensions: RV_sample x wave_mod_shifted)\n",
    "            wave_mod_shifted = wave_obs[0][np.newaxis,:] / (1 + RV_sample*1000/const.c.value)[:,np.newaxis]\n",
    "            flux_mod_shifted = interp1d(wave_mod,flux_mod)(wave_mod_shifted)\n",
    "\n",
    "            # making model and data to a common mean\n",
    "            flux_mod_shifted -= np.nanmean(flux_mod_shifted,axis=1)[:,np.newaxis]\n",
    "            flux_obs -= np.nanmean(flux_obs,axis=1)[:,np.newaxis]\n",
    "\n",
    "            # calculating the summation terms in the chi^2 equation (Gibson+ 2020)\n",
    "            K1 = np.nansum(flux_obs**2/error_obs**2,axis=1)\n",
    "            K2 = np.dot(1./error_obs**2,np.square(flux_mod_shifted).T)\n",
    "            CC = np.dot(flux_obs/error_obs**2,flux_mod_shifted.T)\n",
    "\n",
    "            if self.__dict__['plot_shift']:\n",
    "                plt.figure(figsize=(20,5))\n",
    "                plt.plot(wave_obs[self.ref_spec],flux_obs[self.ref_spec],label='Data')\n",
    "                plt.plot(wave_obs[self.ref_spec],flux_mod_shifted[np.argmax(CC[self.ref_spec])],label='Model')\n",
    "                plt.title('Shift based on maximum CCF value - Order '+str(self.carm_order[order_idx]))\n",
    "                plt.xlabel(r'Wavelength $\\AA$')\n",
    "                plt.ylabel('Normalized flux')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "            K1_all.append(K1) # dimensions: order x frame\n",
    "            K2_all.append(K2) # dimensions: order x frame x RV_sample\n",
    "            CC_all.append(CC) # dimensions: order x frame x RV_sample\n",
    "            N_data.append(len(wave_obs[self.ref_spec]))\n",
    "\n",
    "        # summing over the orders\n",
    "        K1_total = np.sum(K1_all,axis=0)\n",
    "        K2_total = np.sum(K2_all,axis=0)\n",
    "        CC_total = np.sum(CC_all,axis=0)\n",
    "        N_data_total = np.sum(N_data)\n",
    "\n",
    "        # calculating the likelihood for each frame\n",
    "        self.RV_stellar = np.zeros(K1_total.size)\n",
    "        self.RV_stellar_low_std = np.zeros(K1_total.size)\n",
    "        self.RV_stellar_high_std = np.zeros(K1_total.size)\n",
    "        for frame in tnrange(K1_total.size,ascii=True,desc='Frame'):\n",
    "\n",
    "            # calculate chi^2 (dimensions: A_sample x RV_sample)\n",
    "            chi_2 = K1_total[frame] + A_sample[:,np.newaxis]**2 * K2_total[frame][np.newaxis,:]\\\n",
    "            - 2 * A_sample[:,np.newaxis] * CC_total[frame][np.newaxis,:]\n",
    "\n",
    "            # calculate log-likelihood\n",
    "            logL = -N_data_total / 2 * np.log(chi_2/N_data_total)\n",
    "\n",
    "            # normalizing by the maximum value and convert to likelihood\n",
    "            likelihood = np.exp(logL - np.max(logL))\n",
    "\n",
    "            # marginilising the likelihood over the scale factor to get the marginalised likelihood for RV_sample\n",
    "            RV_marg = np.sum(likelihood,axis=0)\n",
    "            A_marg = np.sum(likelihood,axis=1) # same but for scale factor\n",
    "\n",
    "            # extracting the conditional likelihood at the maximum point of the marginalised RV_sample\n",
    "            A_cond = likelihood[:,np.argmax(RV_marg)]\n",
    "\n",
    "            # extracting the +- error and median of RV and the corresponding scale factor\n",
    "            low_RV,med_RV,high_RV = med_n_lim(RV_sample,RV_marg)\n",
    "\n",
    "            if self.__dict__['plot_stellar_RV']:\n",
    "                low_A,med_A,high_A = med_n_lim(A_sample,A_marg)\n",
    "\n",
    "                plt.figure(figsize=(20,5))\n",
    "                plt.subplot(121)\n",
    "                plt.plot(RV_sample,RV_marg)\n",
    "                plt.title('Frame '+str(frame))\n",
    "                plt.title('Frame '+str(frame))\n",
    "                plt.xlabel('RV')\n",
    "                plt.xlim(med_RV+5*low_RV, med_RV+5*high_RV)\n",
    "                plt.subplot(122)\n",
    "                plt.plot(A_sample,A_marg)\n",
    "                plt.xlabel(r'$\\alpha$')\n",
    "                plt.xlim(med_A+5*low_A, med_A+5*high_A)\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "            self.RV_stellar[frame] = med_RV\n",
    "            self.RV_stellar_low_std[frame] = low_RV\n",
    "            self.RV_stellar_high_std[frame] = high_RV\n",
    "            \n",
    "        # formula taken from Exoplanets (Seager, 2010)\n",
    "        ks = (28.4329/np.sqrt(1-param[6]**2))*(param[2])*np.sin(param[1]*np.pi/180)*(param[2]*param[4]/param[5]+param[3])**(-2/3)*(param[0]/365.2455)**(-1/3) # in m/s\n",
    "        ks /= 1000 # in km/s\n",
    "\n",
    "        # barycentric-corrected velocity\n",
    "        def rvs(phase, v_sys):\n",
    "            y = ks * np.sin(2*np.pi*phase+np.pi) + v_sys\n",
    "            return y\n",
    "\n",
    "        radvel = self.RV_stellar + self.data_info['RV_cor']              # data velocity corrected to barycentric\n",
    "        vsys_predict, covariance = curve_fit(rvs, phase, radvel)    # fit v_sys\n",
    "        rv_s = ks * np.sin(2*np.pi*phase+np.pi) + vsys_predict      # in km/s; predicted velocity\n",
    "\n",
    "        plt.figure(figsize=(10,5),dpi=300)\n",
    "        ax1 = plt.subplot(111)\n",
    "\n",
    "        ax1.plot(rel_phase,rv_s,color='c',label = 'predicted RV; $v_{sys}=$'+str(\"%.2f\" %vsys_predict)+r'$\\pm$'+str(np.sqrt(np.diag(covariance)))+' km/s')\n",
    "        ax1.errorbar(rel_phase,np.array(radvel),np.std(radvel),fmt='v', color='red',xuplims=True, xlolims=True,alpha=0.7,label=\"Likelihood\")\n",
    "        plt.axhline(y=np.mean(radvel),ls='--',color='red',alpha=0.8,label='mean RV = '+str(\"%.2f\" %np.mean(radvel))+' km/s')\n",
    "        plt.axvline(x=rel_phase[11],linewidth=0.7,color='black',linestyle='--',alpha=0.5)\n",
    "        plt.axvline(x=rel_phase[16],linewidth=0.7,color='black',linestyle='--',alpha=0.5)\n",
    "        plt.axvline(x=rel_phase[38],linewidth=0.7,color='black',linestyle='--',alpha=0.5)\n",
    "        plt.axvline(x=rel_phase[42],linewidth=0.7,color='black',linestyle='--',alpha=0.5)\n",
    "\n",
    "        ax1.set_xlabel('relative phase from mid-transit',size=13)\n",
    "        ax1.set_ylabel('stellar RV (km/s)',size=13)\n",
    "        ax1.set_title('barycentric-corrected stellar RV')\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        plt.minorticks_on()\n",
    "        plt.tick_params(which=\"both\",direction='in',width=1)\n",
    "        plt.tick_params(which=\"major\",length=6,direction='in')\n",
    "        plt.tick_params(which=\"minor\",length=3,direction='in')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"figures/stellar_RV.pdf\",format=\"pdf\",dpi=200,bbox_inches=\"tight\",pad_inches=0.1)\n",
    "        plt.show(block=False)\n",
    "        plt.clf()\n",
    "     \n",
    "    ############################ function for SysRem ############################\n",
    "\n",
    "    def fit_SysRem_coeff(self, r, error, airmass, iteration):\n",
    "        \n",
    "        \"\"\" r and error have dimensions of (time x wavelength) \"\"\"\n",
    "\n",
    "        a = [airmass]\n",
    "        c = []\n",
    "        for iteran in range(iteration):\n",
    "\n",
    "            # calculate coefficient c\n",
    "            c_up = np.dot((r / error**2).T, a[-1])\n",
    "            c_down = np.dot((1. / error**2).T, a[-1]**2)\n",
    "            c_result = np.zeros(c_up.shape)\n",
    "            np.divide(c_up, c_down, out=c_result, where=c_down!=0) # to account for zero division\n",
    "            c.append(c_result)\n",
    "\n",
    "            # calculatae coefficient a\n",
    "            a_up = np.dot((r / error**2), c[-1])\n",
    "            a_down = np.dot((1. / error**2), c[-1]**2)\n",
    "            a_result = np.zeros(a_up.shape)\n",
    "            np.divide(a_up, a_down, out=a_result, where=a_down!=0) # to account for zero division\n",
    "            a.append(a_result)\n",
    "\n",
    "            # threshold value for iteration\n",
    "            if iteran > 5:\n",
    "                alim = np.abs(a[-1][-1] - a[-5][-1])\n",
    "                clim = np.abs(c[-1][-1] - c[-5][-1])\n",
    "                if alim <= 1e-8 and clim <= 1e-8:\n",
    "                    break\n",
    "\n",
    "        return c[-1],a[-1]\n",
    "    \n",
    "    def SysRem(self, sysrem_iteration, airmass, fit_iteration, plot_sys=False, sys_iter_plot=-1):\n",
    "\n",
    "        \"\"\" the data must NOT contains masked pixels \"\"\"\n",
    "\n",
    "        a_ord, c_ord = [], []\n",
    "        model_ord = []\n",
    "        residual_ord, error_ord, wave_ord = [], [], []\n",
    "        outlier_count = []\n",
    "\n",
    "        for order in tnrange(self.carm_order.size, ascii=True, desc='Order'):\n",
    "\n",
    "            flux_temp = self.flux_sysrem[order].copy()\n",
    "            error_temp = self.error_sysrem[order].copy()\n",
    "            # er_tmp = error_temp.copy() / np.nanmean(flux_temp, axis=0)    # removing zeroth-order systematic\n",
    "            r = flux_temp - np.nanmean(flux_temp, axis=0)                   # removing zeroth-order systematic\n",
    "\n",
    "            # SysRem iteration\n",
    "            a_sys, c_sys = [], []\n",
    "            model_sys = [np.repeat(np.nanmean(flux_temp, axis=0)[np.newaxis, :], repeats=[flux_temp.shape[0]], axis=0)]\n",
    "            for i in range(sysrem_iteration):\n",
    "\n",
    "                # fitting and removing systematics (with airmass is considered as the first systematics)\n",
    "                c, a = self.fit_SysRem_coeff(r, error_temp, airmass, fit_iteration) # Tamuz+ (2005) stated that convergence is ensured regardless the initial values for a and c, thus using airmass as the initial values for the whole iteration is okay\n",
    "                systematics = np.outer(a,c)\n",
    "                r -= systematics\n",
    "                # er_tmp /= systematics\n",
    "\n",
    "                c_sys.append(c)\n",
    "                a_sys.append(a)\n",
    "                model_sys.append(systematics)\n",
    "\n",
    "            # separated from above loop since we wanted to also appending zeroth SysRem iteration a.k.a. before SysRem\n",
    "            residual_sys, error_sys, wave_sys = [], [], []\n",
    "            outlier_count_sys, mask_final = [], []\n",
    "            for i in range(sysrem_iteration+1):\n",
    "                \n",
    "                # removing total systematics until corresponding iteration\n",
    "                model = np.sum(model_sys[:i+1],axis=0)\n",
    "                residual_sys.append(flux_temp - model) #- 1)\n",
    "                error_sys.append(error_temp)#/ model)\n",
    "                wave_sys.append(self.wave_sysrem[order])\n",
    "\n",
    "                ############################# outliers removal #############################\n",
    "\n",
    "                count = 0\n",
    "                if i != 0:\n",
    "\n",
    "                    # identify outliers following Gibson+ (2020)\n",
    "                    simple_model = np.outer(np.median(residual_sys[i],axis=1),np.median(residual_sys[i],axis=0))/np.median(residual_sys[i])\n",
    "                    residual = residual_sys[i] - simple_model\n",
    "                    mask_med = residual[0] < np.inf\n",
    "                    for frame in range(residual_sys[i].shape[0]):\n",
    "                        fit = np.polyfit(wave_sys[i][frame], residual[frame], 10)\n",
    "                        fit_coeff = np.poly1d(fit)\n",
    "                        fit_continuum = fit_coeff(wave_sys[i][frame])\n",
    "                        mask_med *= (residual[frame] < fit_continuum+5*np.std(residual[frame])) *  (residual[frame] > fit_continuum-5*np.std(residual[frame]))\n",
    "\n",
    "                    # identify outliers from std of residuals\n",
    "                    std_residual = np.std(residual_sys[i],axis=0)\n",
    "                    std_nan = std_residual.copy()\n",
    "                    std_nan[std_residual == 0] = np.NaN\n",
    "                    fit = np.polyfit(wave_sys[i][0][~np.isnan(std_nan)], std_nan[~np.isnan(std_nan)], 2)\n",
    "                    std_fit = np.poly1d(fit)(wave_sys[i][0])\n",
    "                    mask_std = np.abs(std_residual - std_fit) < self.sig * np.std(std_residual - std_fit)\n",
    "\n",
    "                    mask = mask_med * mask_std\n",
    "                    residual_sys[i][:,~mask], error_sys[i][:,~mask] = self.maskpix_val, np.inf\n",
    "                    count += np.count_nonzero(~mask)\n",
    "\n",
    "                    # identify outliers at each wavelength bin based on the std of the bin (similar to cosmic rays masking)\n",
    "                    fl = residual_sys[i].copy()\n",
    "                    mask_bin = wave_sys[i][0] > 0\n",
    "                    for wave_bin in range(fl.shape[1]):\n",
    "                        c = sigmaclip(fl[:,wave_bin], low=self.sig, high=self.sig)[0]\n",
    "                        if ~(np.abs(fl[:, wave_bin] - np.mean(c)) < self.sig * np.std(c)).all():\n",
    "                            residual_sys[i][:, wave_bin], error_sys[i][:, wave_bin] = (self.maskpix_val, np.inf)\n",
    "                            count += 1\n",
    "                            mask_bin[wave_bin] = False\n",
    "                    \n",
    "                    mask_final.append(mask * mask_bin)\n",
    "                    outlier_count_sys.append(count) \n",
    "\n",
    "            ############################# plotting #############################  \n",
    "\n",
    "            if plot_sys:\n",
    "\n",
    "                fig,ax = plt.subplots(1,2,figsize=(20,5))\n",
    "                for i in range(len(residual_sys)):\n",
    "                    ax[0].plot((residual_sys / np.square(error_sys))[i][self.ref_spec])\n",
    "                    ax[1].plot(residual_sys[i][self.ref_spec])\n",
    "                ax[0].set_xlabel('Pixel')\n",
    "                ax[0].set_ylabel('Residual / Error^2')\n",
    "                ax[0].set_title('Order = '+str(self.carm_order[order]))\n",
    "                ax[1].set_xlabel('Pixel')\n",
    "                ax[1].set_ylabel('Residual')\n",
    "                ax[1].set_title('Order = '+str(self.carm_order[order]))\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "                plt.figure(figsize=(20,10),dpi=300)\n",
    "                \n",
    "                plt.subplot(311)\n",
    "                x_sample = np.arange(wave_sys[sys_iter_plot][0].size)\n",
    "                b = np.repeat(x_sample[np.newaxis,:],repeats=[wave_sys[sys_iter_plot].shape[0]],axis=0)\n",
    "                plt.pcolormesh(b,np.arange(wave_sys[sys_iter_plot].shape[0]),residual_sys[sys_iter_plot])\n",
    "                plt.ylabel('# Frame')\n",
    "                plt.xlim(x_sample[0], x_sample[-1])\n",
    "\n",
    "                plt.subplot(312)\n",
    "                [plt.plot(x_sample, residual_sys[sys_iter_plot][frame], lw=1) for frame in\n",
    "                range(residual_sys[sys_iter_plot].shape[0])]\n",
    "                plt.title('Order = ' + str(self.carm_order[order]))\n",
    "                plt.ylabel('Normalized Flux')\n",
    "                plt.axhline(np.median(residual_sys[sys_iter_plot]) - self.sig * np.std(residual_sys[sys_iter_plot]), c='red', ls='--',\n",
    "                            lw=1)\n",
    "                plt.axhline(np.median(residual_sys[sys_iter_plot]) + self.sig * np.std(residual_sys[sys_iter_plot]), c='red', ls='--',\n",
    "                            lw=1)\n",
    "                plt.xlim(x_sample[0], x_sample[-1])\n",
    "                \n",
    "                plt.subplot(313)\n",
    "                std_nan = np.std(residual_sys[sys_iter_plot],axis=0)\n",
    "                std_nan[std_nan == 0] = np.NaN\n",
    "                plt.plot(x_sample, std_nan, lw=1)\n",
    "                plt.title('Order = ' + str(self.carm_order[order]))\n",
    "                plt.ylabel('Noise level')\n",
    "                plt.xlim(x_sample[0], x_sample[-1])\n",
    "                plt.xlabel('Pixel')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "            a_ord.append(a_sys)\n",
    "            c_ord.append(c_sys)\n",
    "            model_ord.append(model_sys)\n",
    "            residual_ord.append(residual_sys)\n",
    "            error_ord.append(error_sys)\n",
    "            wave_ord.append(wave_sys)\n",
    "            outlier_count.append(outlier_count_sys)\n",
    "\n",
    "        return a_ord, c_ord, model_ord, residual_ord, error_ord, wave_ord, outlier_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_red(cont_min,func_telluric):\n",
    "\n",
    "    plot = {} # case-sensitive\n",
    "    plot['plot_prep'] = False\n",
    "    plot['plot_norm'] = False\n",
    "    plot['plot_emis'] = False\n",
    "    plot['plot_bad_reg'] = False\n",
    "    plot['plot_out'] = False\n",
    "    plot['plot_strong_tel'] = False\n",
    "    plot['plot_conti'] = False\n",
    "    plot['plot_error'] = False\n",
    "    plot['print_neg'] = False\n",
    "    plot['plot_shift'] = False\n",
    "    plot['plot_stellar_RV'] = False\n",
    "\n",
    "    data_path = 'data/spectrum/'\n",
    "    ref_cont = fits.open(\"data/ref_cont.fits\") # pseudo-continuum of reference spectrum computed using IRAF (spline3 function and sigma_reject = 3)\n",
    "    carm_nir_order = 28 # number of CARMENES NIR order\n",
    "\n",
    "    # read OH and non-OH emission atlas from Oliva+(2015)\n",
    "    oh = (fits.open('sky_emission/OH_Emission_NIR_Atlas.dat.fits'))[1].data\n",
    "    nonoh = (fits.open('sky_emission/non-OH_Emission_NIR_Atlas.dat.fits'))[1].data\n",
    "\n",
    "    # read OH and non-OH emission atlas from Rousselot+(2000)\n",
    "    oh_rousselot = pd.read_excel (r'sky_emission/Emission_NIR_Atlas_Rousselot.xlsx',header=None)\n",
    "    oh_rousselot = oh_rousselot.to_numpy()\n",
    "\n",
    "    # bad_frame = []\n",
    "    bad_frame = [71,43,41,40,19,18,17,16,15,6,5,4,3,2,1,0] # frames with S/N below 50\n",
    "    # bad_frame = [71,44,43,41,40,19,18,17,16,15,6,5,4,3,2,1,0] # frames with S/N below 50 and frame #44 (possible outlier)\n",
    "\n",
    "    bad_order = [9,10,18,19,20,21]\n",
    "    tel_order = [0,8,11,12,13,15,16,17,22,23,24,25] \n",
    "\n",
    "    maskpix_val = 0\n",
    "    resolution = 80400\n",
    "    sigma_threshold = 5\n",
    "\n",
    "    edge_pix = 40\n",
    "    factor_emission = 1\n",
    "    factor_outliers, factor_telluric = 6, func_telluric\n",
    "    continum_minimum = cont_min\n",
    "\n",
    "    threshold_heavy_low,threshold_nonheavy_low = 0.7,0.5\n",
    "    threshold_heavy_ratio,threshold_nonheavy_ratio = 0.3,0.1\n",
    "    binmedfil,bingauss = 501,100\n",
    "\n",
    "    data = Data_Reduction(data_path,oh,nonoh,oh_rousselot,carm_nir_order,bad_frame,bad_order,tel_order,\n",
    "                        ref_cont,maskpix_val,resolution,edge_pix,factor_emission,factor_telluric,factor_outliers,sigma_threshold,\n",
    "                        threshold_heavy_low,threshold_nonheavy_low,threshold_heavy_ratio,threshold_nonheavy_ratio,\n",
    "                        binmedfil,bingauss,continum_minimum,**plot)\n",
    "\n",
    "    flux_star, error_star, wave_star, snr, airmass, humid, data_info = data.data_prep()\n",
    "    wave,flux,error = data.normalization_and_masking()\n",
    "    flux,error,error_outer,wave,data_info = data.perform_reduction(print_mask_count=True,common_conti=True)\n",
    "\n",
    "    class Light_Curve():\n",
    "\n",
    "        def __init__(self,BJD,**kwargs):\n",
    "            self.__dict__.update(**kwargs)\n",
    "            self.bjd = BJD\n",
    "\n",
    "        def calc_LC(self,elliptic=True,plot=False):\n",
    "\n",
    "            R_jup = const.R_jup.value # meter\n",
    "            R_sun = const.R_sun.value # meter\n",
    "            \n",
    "            # defining batman parameters\n",
    "            params = batman.TransitParams()                                         # object to store transit parameters\n",
    "            params.t0 = self.__dict__['T0']                                         # time of inferior conjunction (BJD)\n",
    "            params.per = self.__dict__['P']                                         # orbital period (days)\n",
    "            params.rp = (self.__dict__['R_p']*R_jup)/(self.__dict__['R_s']*R_sun)     # planet radius (units of stellar radii)\n",
    "            params.a = self.__dict__['ap']                                          # semi-major axis (units of stellar radii)\n",
    "            params.inc = self.__dict__['inc']                                       # orbital inclination (degrees)\n",
    "            params.ecc = self.__dict__['e']                                         # eccentricity\n",
    "            params.w = self.__dict__['w']                                           # longitude of periastron (degrees)\n",
    "            params.limb_dark = self.__dict__['limb_dark_model']                     # limb darkening model\n",
    "            params.u = self.__dict__['limb_dark_coeff']                             # limb darkening coefficients\n",
    "\n",
    "            time = np.array(self.bjd)\n",
    "            model = batman.TransitModel(params,time)\n",
    "            flux_batman = model.light_curve(params)\n",
    "\n",
    "            # calculating phase and relative phase from mid-transit\n",
    "            phase = (time - self.__dict__['T0'])/self.__dict__['P'] % 1\n",
    "            relative_phase = []\n",
    "            for ph in range(phase.size):\n",
    "                relative_phase.append(phase[ph] - 1) if phase[ph] > 0.5 else relative_phase.append(phase[ph])\n",
    "            hour_phase = np.array(relative_phase) * self.__dict__['P'] * 24 # in hour (assuming 24 hours a day)\n",
    "\n",
    "            # mask for out-transit frames (outside ingress and egress)\n",
    "            mask_out_transit = 1 - flux_batman\n",
    "            for fl in range(flux_batman.size):\n",
    "                if mask_out_transit[fl] != 0: mask_out_transit[fl] = 1 \n",
    "\n",
    "            # transit weight for cross-correlation calculation\n",
    "            transit_weight = (1. - flux_batman)/np.max(1. - flux_batman)\n",
    "        \n",
    "            ########## Estimating the time for first to fourth contact (calculated following Exoplanets, 2010) ##########\n",
    "\n",
    "            ap, inc, e, w = self.__dict__['ap'],self.__dict__['inc'],self.__dict__['e'],self.__dict__['w']\n",
    "            Tp, P, R_p, R_s = self.__dict__['Tp'],self.__dict__['P'],self.__dict__['R_p']*R_jup,self.__dict__['R_s']*R_sun\n",
    "\n",
    "            b = ap * np.cos(math.radians(inc)) * (1 - e**2)\\\n",
    "                / (1 + e*np.sin(math.radians(w))) # impact parameter\n",
    "            \n",
    "            if elliptic:\n",
    "                total_duration = P / np.pi * np.arcsin(1/ap * (np.sqrt((1+R_p/R_s)**2 - b**2))/(np.sin(math.radians(inc)))) # from first to fourth contact\n",
    "                full_duration = P / np.pi * np.arcsin(1/ap * (np.sqrt((1-R_p/R_s)**2 - b**2))/(np.sin(math.radians(inc)))) # from second to third contact\n",
    "                ingress_to_egress = (total_duration - full_duration)/2\n",
    "            else:\n",
    "                ingress_to_egress = P / (ap*np.pi) / np.sqrt(1-b**2) * R_p / R_s\n",
    "\n",
    "            intrans_frame = []\n",
    "            for idx in range(len(flux_batman)-1):\n",
    "                if np.abs(flux_batman[idx]-flux_batman[idx+1]) > 0.:\n",
    "                    intrans_frame.append(idx)\n",
    "            intrans_frame[-1] += 1 # to anticipate last index\n",
    "\n",
    "            contact_time = [time[intrans_frame[0]], time[intrans_frame[0]]+ingress_to_egress,time[intrans_frame[-1]]-ingress_to_egress,time[intrans_frame[-1]]]\n",
    "            contact_index = np.argmin(np.abs(time - np.asarray(contact_time)[:,np.newaxis]),axis=1)\n",
    "            \n",
    "            # calculate true anomaly\n",
    "            phase_Tp = (np.array(self.bjd) - Tp)/P % 1\n",
    "            M = (2 * np.pi * phase_Tp)\n",
    "            E = np.zeros((len(M)))\n",
    "            for i in range(len(E)):\n",
    "                E[i] = solve_E(M[i],e)\n",
    "            v_phase = np.arctan(np.sqrt((1+e)/(1-e))*np.tan(E/2)) * 2 # in radians\n",
    "\n",
    "            ###############################################################################################\n",
    "            if plot:\n",
    "\n",
    "                for idx,fl in enumerate(flux_batman):\n",
    "                    print(\"frame \"+str(idx)+\", bjd = \"+str(time[idx])+\", flux = \"+str(flux_batman[idx]))\n",
    "\n",
    "                print()\n",
    "                print('Central transit:')\n",
    "                print(\"Frame #\"+str(np.argmin(flux_batman))+\", BJD = \"+str(time[np.argmin(flux_batman)])\\\n",
    "                    +\", Phase hours = \"+str(hour_phase[np.argmin(flux_batman)])\\\n",
    "                        +\", fluxmin = \"+str(flux_batman[np.argmin(flux_batman)]))\n",
    "\n",
    "                fig,ax1 = plt.subplots(figsize=(7,5),dpi=100)\n",
    "                ax1.scatter(time,flux_batman,label=str(self.__dict__['limb_dark_model']))\n",
    "                ax1.set_xlabel('BJD - 2400000')\n",
    "                ax1.set_ylabel('Relative flux')\n",
    "                ax1.axvline(x=contact_time[0],c='red',lw=1,alpha=0.5,ls='--')\n",
    "                ax1.axvline(x=contact_time[1],c='red',lw=1,alpha=0.5,ls='--')\n",
    "                ax1.axvline(x=contact_time[2],c='red',lw=1,alpha=0.5,ls='--')\n",
    "                ax1.axvline(x=contact_time[3],c='red',lw=1,alpha=0.5,ls='--')\n",
    "                # ax1.axvline(x=time[44],c='red',lw=1,alpha=0.5,ls='--')\n",
    "                ax2 = ax1.twiny()\n",
    "                ax2.scatter(hour_phase,flux_batman)\n",
    "                ax2.set_xlabel('Hours from mid-transit')\n",
    "                ax2.axvline(x=0,c='red',lw=1,alpha=0.5,ls='--')\n",
    "                fig.tight_layout()\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "            return flux_batman,phase,phase_Tp,relative_phase,hour_phase,v_phase,mask_out_transit,transit_weight,contact_index\n",
    "        \n",
    "    # param for batman package\n",
    "    param = {} # case-sensitive\n",
    "\n",
    "    # convert BJD_UTC to BJD_TDB for T0\n",
    "    BJD_UTC = 54456.78760                           # transit midpoint, BJD_UTC-2400000 (Zhang+ 2018)\n",
    "    BJD_TDB = BJD_UTC + (32.184 + 34)/86400         # 34 is the number of leap seconds as of April 8th 2011 (Zhang data) since 1961\n",
    "    param['T0'] = BJD_TDB\n",
    "\n",
    "    # convert JD_UTC to BJD_TDB for Tp\n",
    "    JDUTC = time.Time(63208.799999999814+2400000, format='jd', scale='utc') # epoch of periastron in JD (Ment+ 2018)\n",
    "    param['Tp'] = barycorrpy.utc_tdb.JDUTC_to_BJDTDB(JDUTC,starname='HD 149026', lat=37.2236, longi=-2.54625, alt=2168)[0][0] - 2400000\n",
    "\n",
    "    param['P'] = 2.87588874                     # period, days (Zhang+ 2018)\n",
    "    param['R_p'] = 0.811                        # planet radius, Jupiter radii (Bonomo+ 2017)\n",
    "    param['R_s'] = 1.41                         # star radius, Sun radii (Stassun+ 2017)\n",
    "    semi_major = 0.04364                        # semi-major axis, AU (Bonomo+ 2017)\n",
    "    param['ap'] = semi_major*const.au.value\\\n",
    "        /(param['R_s']*const.R_sun.value)       # stellar radii\n",
    "    param['inc'] = 84.50                        # inclination, degrees (Bonomo+ 2017)\n",
    "    param['e'] = 0.0                              # eccentricity\n",
    "    param['w'] = -90                             # longitude of periastron, degrees\n",
    "    param['Vsys'] = -17.92\n",
    "\n",
    "    # calculated from https://exoctk.stsci.edu/limb_darkening using NIRSpec.F100LP.G140H.S200A1 bandpass\n",
    "    mu_nl = [0.619, -0.057,0.007,-0.024]        # non-linear limb darken\n",
    "    mu_qd = [0.075, 0.372]                      # quadratic limb darken\n",
    "    mu_lin = 0.39                               # linear limb darken\n",
    "    param['limb_dark_model'] = 'quadratic'\n",
    "    param['limb_dark_coeff'] = mu_qd\n",
    "\n",
    "    # convert JD_UTC to BJD_TDB for observations\n",
    "    JDUTC = time.Time(data_info['JD']+2400000, format='jd', scale='utc')\n",
    "    BJD_TDB_obs = barycorrpy.utc_tdb.JDUTC_to_BJDTDB(JDUTC,starname='HD 149026', lat=37.2236, longi=-2.54625, alt=2168)[0] - 2400000\n",
    "\n",
    "    lc = Light_Curve(BJD_TDB_obs,**param)\n",
    "    flux_batman,phase,phase_Tp,relative_phase,hour_phase,v_phase,mask_out_transit,transit_weight,contact_index = lc.calc_LC()\n",
    "\n",
    "    wave_sysrem, flux_sysrem, error_sysrem, maskpix = [], [], [], []\n",
    "    for idx,order in enumerate(data_info['CARMENES_order']):\n",
    "\n",
    "        # removing masked pixels\n",
    "        wave_temp,flux_temp,error_temp,mask = mask_pix(wave[idx],flux[idx],error_outer[idx])\n",
    "\n",
    "        # calculate median spectrum\n",
    "        median = np.nanmedian(flux_temp,axis=0)\n",
    "\n",
    "        # normalize by median spectrum\n",
    "        errnorm = np.array(error_temp)[:] / median\n",
    "        fluxnorm = np.array(flux_temp)[:] / median\n",
    "\n",
    "        wave_sysrem.append(np.array(wave_temp))\n",
    "        flux_sysrem.append(fluxnorm)\n",
    "        error_sysrem.append(errnorm)\n",
    "        maskpix.append(mask)\n",
    "\n",
    "    sysrem_iteration = 15\n",
    "    fit_iteration = 20000\n",
    "    airmass = data_info['airmass']\n",
    "    data.flux_sysrem, data.error_sysrem, data.wave_sysrem = flux_sysrem.copy(),error_sysrem.copy(),wave_sysrem.copy() # case-sensitive\n",
    "\n",
    "    # running SysRem\n",
    "    a_model, c_model, sysrem_model, residual_flux, residual_error, residual_wave, outlier_count = data.SysRem(sysrem_iteration,airmass,fit_iteration,plot_sys=False)\n",
    "\n",
    "    # assigning the dimension of the original array\n",
    "    flux_final = np.zeros((flux.shape[0],sysrem_iteration+1,flux.shape[1],flux.shape[2]))\n",
    "    wave_final = flux_final.copy()\n",
    "    error_final = flux_final.copy()\n",
    "    error_final[:,:,:,:] = np.inf\n",
    "    a_final = np.array(a_model)\n",
    "    c_final = np.zeros((flux.shape[0],sysrem_iteration+1,flux.shape[2]))\n",
    "    for idx,order in enumerate(data_info['CARMENES_order']):\n",
    "        for sysiter in range(sysrem_iteration+1):\n",
    "            if sysiter != 0: c_final[idx][sysiter-1][maskpix[idx]==True] = c_model[idx][sysiter-1]\n",
    "            for frame in range(flux_final.shape[2]):\n",
    "                flux_final[idx][sysiter][frame][maskpix[idx]==True] = residual_flux[idx][sysiter][frame]\n",
    "                error_final[idx][sysiter][frame][maskpix[idx]==True] = residual_error[idx][sysiter][frame]\n",
    "                wave_final[idx][sysiter][frame] = wave[idx][frame]\n",
    "\n",
    "    # saving results to HDF5 files\n",
    "\n",
    "    for sysiter in range(flux_final.shape[1]):\n",
    "\n",
    "        # making hdf5 file for each SYSREM iteration\n",
    "        with h5py.File('data/hdf5/HD149026b-after-#'+str(sysiter)+'-SYSREM-iteration-sys-continuum_'+str(continum_minimum)+'eta_'+str(func_telluric)+'.hdf5', 'w') as h5f_raw:\n",
    "\n",
    "            for order in range(flux_final.shape[0]):\n",
    "\n",
    "                # saving flux\n",
    "                fluxdata = flux_final[order][sysiter].copy()\n",
    "                h5f_raw.create_dataset('flux-order-'+str(order),data=fluxdata)\n",
    "\n",
    "                # saving the propagation of whatever error passed into SysRem\n",
    "                errdata = error_final[order][sysiter].copy()\n",
    "                h5f_raw.create_dataset('error-poisson-order-'+str(order),data=errdata)\n",
    "\n",
    "                # saving wavelength\n",
    "                h5f_raw.create_dataset('wv-vac-order-'+str(order),data=wave_final[order][sysiter])\n",
    "\n",
    "                if sysiter != 0:\n",
    "\n",
    "                    # saving a and c coefficient\n",
    "                    h5f_raw.create_dataset('a-coeff-order-'+str(order),data=a_final[order][sysiter-1])\n",
    "                    h5f_raw.create_dataset('c-coeff-order-'+str(order),data=c_final[order][sysiter-1])\n",
    "\n",
    "            h5f_raw.create_dataset('airmass',data=data_info['airmass'])\n",
    "            h5f_raw.create_dataset('rv_cor',data=data_info['RV_cor'])\n",
    "            h5f_raw.create_dataset('bjd',data=data_info['BJD'])\n",
    "            h5f_raw.create_dataset('mjd',data=data_info['MJD'])\n",
    "            h5f_raw.create_dataset('exp_time',data=data_info['exptime'])\n",
    "            h5f_raw.create_dataset('carm_order',data=data_info['CARMENES_order'])\n",
    "            h5f_raw.create_dataset('phase',data=phase)\n",
    "            h5f_raw.create_dataset('rel_phase',data=relative_phase)\n",
    "            h5f_raw.create_dataset('hour_phase',data=hour_phase)\n",
    "            h5f_raw.create_dataset('out_transit_mask',data=mask_out_transit)\n",
    "            h5f_raw.create_dataset('transit_weight',data=transit_weight)\n",
    "            h5f_raw.create_dataset('contact_index',data=contact_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocess as mp\n",
    "\n",
    "# factel = [2,4,6,8,10,12,14,16,18,20,22,24,26,28,29,30]\n",
    "# # t = time.time()\n",
    "# with mp.Pool(8) as pool:\n",
    "#     r = pool.map(data_red,factel)\n",
    "# # print('multi: ' +str(time.time()-t))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04651d232034be491ba422169f398d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "For each spectrum, before the masking = 114240, after masking = 70605 (38.2% non-useful data points).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996e5b16d4ac45bb99acec9e7177c13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Order:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "For each spectrum, before the masking = 114240, after masking = 70326 (38.44% non-useful data points).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f3e881b70b4a5a8a42d6fc1fda8159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Order:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "For each spectrum, before the masking = 114240, after masking = 70161 (38.58% non-useful data points).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629e10ca092144fba966a677426c0c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Order:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "For each spectrum, before the masking = 114240, after masking = 69939 (38.78% non-useful data points).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d059c76b7f842868125b468b8ae12e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Order:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "For each spectrum, before the masking = 114240, after masking = 69688 (39.0% non-useful data points).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd8895393ae4ea5a6c3c9d582243781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Order:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "For each spectrum, before the masking = 114240, after masking = 69554 (39.12% non-useful data points).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5bacbf0a0249168fb9b079c38339c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Order:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "(56, 28, 4080)\n",
      "For each spectrum, before the masking = 114240, after masking = 69414 (39.24% non-useful data points).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270e09488a664b8bb30a8c5fb5d1cafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Order:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factel = [20,22,24,26,28,29,30]\n",
    "for i in tnrange(len(factel)):\n",
    "    data_red(0.3,factel[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
